<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RabbitMQ基础小结]]></title>
    <url>%2F2018%2F09%2F11%2Frabbitmq%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是RabbitMQ？RabbitMQ作为消息中间件，可以平衡数据库压力，实现入库的异步操作，是一个在AMQP基础上完成的，可复用的企业消息系统。Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 producer：消息生产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 原理图： 思维导图： 参考：https://www.cnblogs.com/linkenpark/p/5393666.html 2.RabbitMQ的工作模式？ 简单模式 提供者将消息写入队列，如果队列中没有其他消息，则消息会在第一时间被处理消费者会实时监控队列中是否有消息，如果有则进行处理 工作模式／双工模式 由一个生产者生产，多个消费者进行争抢，谁抢到谁执行 发布订阅模式（fanout） 生产者通过交换机，将消息发往不同的队列，每个消费者只关注自己的队列，对自己的队列消息进行消费（一个消息被消费多次，适合群发和广播） 路由模式（redirect） 消费者通过交换机，根据不同的路由key将消息发往不同的队列中，通过路由key的比较，将消息发往特定消费者的队列中（特殊的订阅模式） 主题模式（topic） 通过通配符*（一个或多几个字符）或#（任意类型，可以匹配多个字符串）将消费发往匹配的路由key的消息队列中（特殊的路由模式） 参考：http://www.rabbitmq.com/getstarted.html 3.具体应用场景？4.如何保证消息队列的消息一定被消费？如何保证消息不被重复消费？如何保证消息的执行顺序？Rabbit通过Ack机制机制上，通过先缓存发送的消息，直到得到Ack再删除message，否则从新发送消息，可开启一条线程来进行消息超时的检查。来确保消费被正确发送和消费。 开启持久化策略，保证服务器在宕机时，消息不会丢失，当会影响性能。当消息被消费，但返回ACK出现问题，会导致，消息重发，重复消费，需要保证业务逻辑的幂等性。可以用db记录消息的消费状态（取消／失败／成功）表示已经被消费了。直接返回ack消息。 5.RabbitMQ在项目中的使用步骤？spring-rabbit整合？ 导入jar包。（新版本的包各种报错，搞不来…） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 创建rabbitmq.properties文件。 12345rabbit.ip=172.16.81.134rabbit.port=5672rabbit.username=lzqrabbit.password=123virtual-host=/ 配置spring-Rabbit-send.xml文件，创建连接工厂／创建交换机（可配置自动持久化）／定义rabbitTemplate模版配置连接工厂 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation="http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd"&gt; &lt;!-- 定义RabbitMQ的连接工厂 --&gt; &lt;rabbit:connection-factory id="connectionFactory" host="$&#123;rabbit.ip&#125;" port="$&#123;rabbit.port&#125;" username="$&#123;rabbit.username&#125;" password="$&#123;rabbit.password&#125;" virtual-host="$&#123;virtual-host&#125;"/&gt; &lt;!-- MQ的管理，包括队列、交换器等 --&gt; &lt;rabbit:admin connection-factory="connectionFactory"/&gt; &lt;!-- 定义交换机 自动声明 持久化--&gt; &lt;rabbit:direct-exchange name="orderExchange" auto-declare="true" durable="true" /&gt; &lt;!--定义rabbit模板--&gt; &lt;rabbit:template id="rabbitTemplate" connection-factory="connectionFactory" exchange="orderExchange"/&gt;&lt;/beans&gt; 配置连接工厂／定义消息队列／定义交换机（绑定队列，定义路由key）／定义监听，配置监听服务，方法，监听的队列 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation="http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd"&gt; &lt;!-- 1.定义RabbitMQ的连接工厂 --&gt; &lt;rabbit:connection-factory id="connectionFactory" host="$&#123;rabbit.ip&#125;" port="$&#123;rabbit.port&#125;" username="$&#123;rabbit.username&#125;" password="$&#123;rabbit.password&#125;" virtual-host="$&#123;virtual-host&#125;" /&gt; &lt;!-- MQ的管理，包括队列、交换器等 --&gt; &lt;rabbit:admin connection-factory="connectionFactory" /&gt; &lt;!-- 定义消息队列 --&gt; &lt;rabbit:queue name="orderQueue" auto-declare="true"/&gt; &lt;!-- 定义交换机，并且完成队列和交换机的绑定 --&gt; &lt;rabbit:direct-exchange name="orderExchange" auto-declare="true"&gt; &lt;rabbit:bindings&gt; &lt;!-- key：路由key --&gt; &lt;rabbit:binding queue="orderQueue" key="save.order"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!--自定义bean处理消息队列中的内容--&gt; &lt;bean id="rabbitOrderListener" class="net.keenlee.pakchoi.test.listener.RabbitOrderListener"&gt;&lt;/bean&gt; &lt;!-- 定义监听 --&gt; &lt;rabbit:listener-container connection-factory="connectionFactory" acknowledge="auto"&gt; &lt;!-- 监听一个队列，当队列中有消息，就会自动触发类.方法，传递消息就作为方法的参数，根据方法声明的参数强转 --&gt; &lt;rabbit:listener ref="rabbitOrderListener" method="onMessage" queues="orderQueue"/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 使用rabbitTemplate操作消息队列 发送者： 123456789101112131415161718192021package net.keenlee.pakchoi.test.controller;import net.keenlee.pakchoi.test.service.RabbitMQOrderService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class TestRabbitmqController &#123; @Autowired RabbitMQOrderService rabbitMQOrderService; @RequestMapping("saveOrder") @ResponseBody public void saveOrder()&#123; //下单 rabbitMQOrderService.saveOrder(); &#125;&#125; 123456package net.keenlee.pakchoi.test.service;public interface RabbitMQOrderService &#123; void saveOrder();&#125; 12345678910111213141516171819202122package net.keenlee.pakchoi.test.service.impl;import net.keenlee.pakchoi.test.service.RabbitMQOrderService;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class RabbitMQOrderServiceImpl implements RabbitMQOrderService &#123; @Autowired AmqpTemplate rabbitTemplate; @Override public void saveOrder() &#123; //下单 System.out.println("订单保存成功！"); System.out.println("向消息队列发送消息..."); //发送邮件 rabbitTemplate.convertAndSend("save.order","恭喜你，下单成功！！！"); &#125;&#125; 接收者： 12345678910111213141516171819202122package net.keenlee.pakchoi.test.listener;import org.springframework.amqp.core.Message;import org.springframework.amqp.core.MessageListener;import java.io.UnsupportedEncodingException;public class RabbitOrderListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; try &#123; sendEmail(new String(message.getBody(),"utf-8")); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; public void sendEmail(String msg)&#123; System.out.println("接收到消息队列的消息:"+msg); &#125;&#125; 运行结果： 改造1:断开重试机制 改造2:消息确认消费 改造3:保证消息幂等性 改造4:…]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat配置基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fmycat%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.数据库热备原理？ 二进制日志文件。当主数据库发生更新时，会将更新的数据写入二进制文件中。 I／O线程。从机实时监听二进制文件是否有更新操作，如果有更新操作则读取更新的内容。 中继日志。保存主库更新的数据（临时存储）。 SQl线程。将中继日志的信息更新到数据库中。 2.如何配置主从数据库？ 为mysql的配置文件my.cnf，默认条件下的二进制日志文件是关闭的。 实现主从挂载（互为主从：双机热备）注意： server-id不能重复。 服务器不能连接：关闭防火墙／IP地址是否正确。 找不到日志文件：日志文件写错。 主从同步应注意哪些问题？当进行主从挂载时，post位置可以从0开始，但必须保证主从库表一致。进行主从同步时，都是由同一个sql转储文件导入之后再进行数据挂载，这样能极大的降低从库的负载，减轻数据不同步的影响 3.主从同步延时/不一致解决方案？4.mycat的作用？mycat是一个高性能的数据库中间件。 支持心跳检测机制，实现数据库的高可用 实现数据库的读写分离和主从复制 支持分库分表 5.mycat主从搭建？主要步骤及配置？mysql数据库实现了完善的数据库备份机制。 搭建主库： 开放数据库权限，导入数据库文件。 1grant all on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;root&apos;;（测试的时候all,开启起了所有权限，这是危险的） 开启二进制文件,编辑mysql系统配置文件my.cnf(指定mysql端口，数据库位置) 123456789[mysqld]#指定数据库存储路径datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysql#制定serverid，不能与集群中另一个相同server-id=1#开启二进制日志文件log-bin=mysql-bin 重启服务，检查二进制文件是否启动 cd /var/lib/mysql是否存在mysql-bin.000001。每次重启编号加1。 搭建从库： 与主库一样修改my.cnf文件，但server-id不能一样 主从连接: 查看主库状态SHOW MASTER status，查看它的position 1show master status 实现主从挂载 1234567#实现主从的挂载 主机的ip 端口 #用户名和密码 二进制日志文件 文件的位置change MASTER to MASTER_HOST=&quot;192.168.126.137&quot;,MASTER_PORT=3306,MASTER_user=&quot;root&quot;,MASTER_PASSWORD=&quot;root&quot;,MASTER_LOG_FILE=&quot;mysql-bin.000001&quot;,MASTER_LOG_POS=120 启动从服务器，查看从服务状态 12#检测主从服务启动是否正确 （查看Slave_IO_Runing=yes,Slave_SQL_Runing=yes）show SLAVE STATUS 如果slave_IO_Running和slave_SQL_Running的值为yes说明搭建成功。注意：单纯的主从会存在问题。当主库宕机整个服务都将无法使用，假设配置了一主多从，当主机宕机，从机成为新的主机，但与原有的从机不存在主从关系，导致数据无法同步，解决双机热备。 配置jdk，编写两个配置文件schema.xml和server.xml两个配置文件 schema.xml 主要配置： 配置dataNode：表示数据库节点信息（节点名称／节点主机／数据库名称） 配置dataHost：表示节点主机（节点主机名／最大连接数／最小连接数／读写分离策略（balance：0:读操作发往writeHost。1:读操作发往readHost和闲置主节 writeType：0:所有的写操作都会发往第一台writeHost中。1:写操作随机发往writeHost主机／数据库类型／数据库驱动／高可用切换类型switchType：-1不自动切换，1，自动切换心跳检测heratbeat）） 配置writeHost及对应的readHost（名字／IP：port／用户／密码） 123456789101112131415161718192021222324&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!--name属性是自定义的 dataNode表示数据库的节点信息--&gt; &lt;schema name="mytest" checkSQLschema="false" sqlMaxLimit="100" dataNode="mytest"&gt;&lt;/schema&gt; &lt;!--定义节点名称/节点主机/数据名称--&gt; &lt;dataNode name="mytest" dataHost="localhost1" database="mytest" /&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select 1&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="192.168.106.137:3306" user="root" password="Lzq_0221"&gt; &lt;!--读数据库--&gt; &lt;readHost host="hostS1" url="192.168.106.138:3306" user="root" password="Lzq_0221" /&gt; &lt;/writeHost&gt; &lt;!-- 需要实现双机热备 --&gt;&lt;writeHost host="hostM2" url="192.168.106.138:3306" user="root" password="Lzq_0221"&gt; &lt;readHost host="hostS1" url="192.168.106.137:3306" user="root" password="Lzq_0221" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; server.xml主要配置： 设置防火墙／设置用户标签（用户名／用户密码／数据库要与schema中一致） 1234567&lt;!--用户标签--&gt; &lt;user name="root"&gt; &lt;property name="password"&gt;Lzq_0221&lt;/property&gt; &lt;!--与schema.xml中的配置相同 注意数据库的大小写--&gt; &lt;property name="schemas"&gt;mytest&lt;/property&gt; &lt;property name="readOnly"&gt;false&lt;/property&gt; &lt;/user&gt; 通过连接mycat来操作数据库 规则 rule.xml:mycat分片规则（分库分表）定义的规则为对id使用mod-log将数据库平均拆分。用function中count指定分配的物理库的数量。 支持的规则：固定分片hash算法／范围约定／求模法／日期列分区／一致性hash（可以解决动态扩容的问题） 6.分库分表策略，分库分表配置？ 答：使用mycat分片实现分库分表……]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>mycat</tag>
        <tag>数据库中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fdubbo%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是dubboApache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 2.dubbo的特性？ 面向接口代理的高性能RPC调用提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节。 智能负载均衡内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。 服务自动注册与发现支持多种注册中心服务，服务实例上下线实时感知。 高度可扩展能力遵循微内核+插件的设计原则，所有核心能力如Protocol、Transport、Serialization被设计为扩展点，平等对待内置实现和第三方实现。 运行期流量调度内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现灰度发布，同机房优先等功能。 可视化的服务治理与运维提供丰富服务治理、运维工具：随时查询服务元数据、服务健康状态及调用统计，实时下发路由策略、调整配置参数。 3.Dubbo工作原理？答：1.消费者2.提供者3.监视器（monitor）4.注册中心（zookeeper）1.消费者配置注册中心地址，添加依赖的服务接口及服务id2.提供者配置注册中心地址，配置dubbo服务接口，暴露服务接口，创建具体实现接口服务的bean 4.rpc原理5.Spring整合Dubbo？前提：搭建好了zookeeper作为注册中心。 创建Duubo接口 1234public interface StudentsDubboServiceInterface &#123; List&lt;Students&gt; findAll();&#125; 生产者 service实现dubbo接口 1234567891011@Servicepublic class StudentsServiceImpl implements StudentsDubboServiceInterface &#123; @Autowired StudentsMapper studentsMapper; @Override public List&lt;Students&gt; findAll() &#123; return studentsMapper.selectAll(); &#125;&#125; 配置生产者 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;!--定义了提供方应用信息，用于计算依赖关系；在 dubbo-admin 或 dubbo-monitor 会显示这个名字，方便辨识--&gt; &lt;dubbo:application name="demotest-provider" owner="programmer" organization="dubbox"/&gt; &lt;!--使用 zookeeper 注册中心暴露服务，注意要先开启 zookeeper--&gt; &lt;!--&lt;dubbo:registry address="zookeeper://192.168.106.128:2181"/&gt;--&gt; &lt;dubbo:registry protocol="zookeeper" address="192.168.106.128:2181,192.168.106.129:2181,192.168.106.130:2181" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;!--使用 dubbo 协议实现定义好的 api.PermissionService 接口--&gt; &lt;dubbo:service interface="net.keenlee.pakchoi.dubbo.service.StudentsDubboServiceInterface" ref="studentsDubboService" protocol="dubbo" timeout="10000" /&gt; &lt;!--具体实现该接口的 bean--&gt; &lt;bean id="studentsDubboService" class="net.keenlee.pakchoi.manager.service.impl.StudentsServiceImpl"/&gt;&lt;/beans&gt; 消费者 service实现dubbo接口 1234567891011@Servicepublic class StudentsServiceTestImpl implements StudentsServiceTest &#123; @Autowired StudentsDubboServiceInterface studentsDubboServiceInterface; @Override public List&lt;Students&gt; findAll() &#123; return studentsDubboServiceInterface.findAll(); &#125;&#125; 配置消费者 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="demotest-consumer" owner="programmer" organization="dubbox"/&gt; &lt;!--向 zookeeper 订阅 provider 的地址，由 zookeeper 定时推送--&gt; &lt;!--&lt;dubbo:registry address="zookeeper://192.168.106.128:2181"/&gt;--&gt; &lt;dubbo:registry protocol="zookeeper" address="192.168.106.128:2181,192.168.106.129:2181,192.168.106.130:2181" /&gt; &lt;!--使用 dubbo 协议调用定义好的 api.PermissionService 接口--&gt; &lt;dubbo:reference id="studentsDubboService" interface="net.keenlee.pakchoi.dubbo.service.StudentsDubboServiceInterface"/&gt;&lt;/beans&gt; dubbo官网：http://dubbo.apache.org/zh-cn/]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fnginx%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是nginx？Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。 2.反向代理？项目中使用场景？反向代理是指以代理服务器来接受网络请求，将请求转发给内部服务器，并将结果返回给给客户端。实现动静分离，在进行图片回显时由于我们无法直接访问服务器存在本地磁盘的图片文件，只能通过一个虚拟路径进行访问，该请求被代理服务器拦截，将虚拟路径替换为真实路径，最终通过代理将结果进行返回。 3.nginx负载均衡？ 轮询机制：upstream 集群名称{}:根据配置文件的顺序依次进行服务的调用。 权重机制：在集群中添加weight属性。 ip_hash:根据用户的IP地址进行hash运算，最终算出特定的一台机器进行数据转发（如果配置ip_hash权重和轮询将不起作用）。 backup：备用机机制，当主服务正忙或者断电／宕机时，备用机将会起作用。 4.nginx基本配置？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#运行用户#user nobody;#启动进程，通常设置成和cpu的数量相等worker_processes 1;#全局错误日志文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid文件#pid logs/nginx.pid;events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024;&#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k;#设定虚拟主机配置server&#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log 错误日志路径; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125;location ／&#123; # proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root :定义服务器的默认网站根目录位置; index:定义首页索引文件的名称； proxy_pass: http://localhost:8091;//转发请求 或者proxy_pass: http://7080 #跟upstream合用 #定义超时策略 proxy_connect_timeout 1 proxy_send_timeout 1 proxy_read_timeout 1 &#125; #重定向：相对于proxy_pass，地址栏的路径会改变 location ^~ /oauth2/ &#123; rewrite /(.*) https://$host/$1 permanent; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125;&#125;#指定proxy_pass代理路径,均衡策略，最大连接失败次数，超时失败时间upstream 7080 &#123; server ip1:7080 weight=5 max_fails=2 fail_timeout=30s; #server ip1:7080 weight=3 max_fails=2 fail_timeout=30s; #server ip2:7080 weight=2 max_fails=2 fail_timeout=30s;&#125;#引入其它配置文件include servers/*;include ***.conf; &#125; 5.正向代理与反向代理的区别？6.nginx如何实现tomcat的高可用？在nginx连接服务器期间，会自动向服务器发送健康检查机制（ping/发起一次请求）如果服务器失败的次数达到最大失败次数（max_fail）上限，在这个检测周期(fail_timeout)中，将不会再有请求转发到这个服务器上，直到下一次检测周期。 7.nginx进程模型？事件处理？8.与其他服务器的对比？9.nginx防盗链？]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础小结]]></title>
    <url>%2F2018%2F08%2F08%2FRedis%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[什么是redis？redis是一种内存中的数据结构存储系统，它可以用作数据库／缓存／消息中间件。 redis常见的作用？项目中使用redis作为缓存使用，这样可以减轻数据库的压力，同时可以加快一些常用数据的查询效率。对于查询多修改少的数据进行缓存。 数据库中的数据与缓存中的数据如何实现同步？同步是同程序员代码来实现控制的。具体操作是： 当缓存中不存在数据时，先去数据库查询，成功后更新缓存。 当缓存中存在数据时，首先更新缓存中的数据，同时会生成对应的修改操作的key一张记录表，之后redis后台会有相关的机制（待查。。。），读取该列表的保存的key，找到对应的数据，同步更新到数据库中。 缓存中的数据如何实现持久化操作？为什么要进行持久化操作？redis中有完善的持久化策略。 RDB（默认）：这种备份方式的效率最高，在规定的时间周期内为数据进行备份，如在多少秒内进行了多少次set操作则进行一次备份，保存在rdb文件中，当redis重启之后会根据配置文件找到对应的备份文件还原数据。 AOF：实时的持久化策略，性能相对较低。有三种模式： ​ always：执行一次set就持久化一次。 ​ everysec：每隔一秒进行一次持久化（常用）。 ​ no：持久化的时间由操作系统决定。（一般不配）因为redis中的数据保存在内存中，如果出现宕机或断电的情况，会使内存中的数据丢失。如果是当作数据库和消息队列来使用时，这样的数据是绝不允许丢失的。 redis如何管理维护自身内存大小的？redis有6种内存优化管理的策略。 lru：删除最近最少使用的数据 volatile-lru:删除设定了超时时间的数据中找最近最少使用的数据 allkey-lru：所有的key根据lru算法进行删除 volatile-random：在设定了超时时间的数据中进行随机删除 allkey-random：在所有的key中进行随机删除 volatile-ttl：在设置了超时时间的数据中删除，将要超时的数据 noevication：默认策略，不会进行删除，当进行set操作时会返回报错信息 缓存中的数据结构是怎样的？支持的数据类型有哪些？redis数据是通过key-value方式进行存储的。 redis支持五种基础数据类型： string（字符串）：redis字符串是动态的，内部结构类似于Java的ArrayList，字符串最大长度为 512M 。 hash（哈希）：类似于Java的HashMap，数组+链表。不同的是字典的值只能是字符串，同时采用的是渐进式rehash策略。即保存了，新旧两个hash表，知道rehash全部完成，删除旧的。 hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。 hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。 list（列表）：类似于Java的LinkList（quickList），当列表元素较少时，采用ziplist（压缩列表）结构，连续的存储空间，节省存储空间，减轻内存碎片化 。当列表元素较多时，采用quicklist。将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 set（集合）：类似于Java的HashSet，可用作全局去重 zset（sorted set：有序集合）：类似于SortedSet+HashMap，内部是跳跃列表的结构。 高级数据类型：HyperLogLog（），Geo、Pub/Sub （不成熟，基本被放弃），stream（5.0）支持消息订阅，想代替mq？ 简述redis分片？为什么需要redis分片？分片：根据某种规则… 分片的原因： redis内存满了，分片可实现动态扩容 redis服务器可能宕机，分片可以让每个节点保存一部分数据，宕机只会影响部分数据 简述redis哨兵机制？使用哨兵机制实现redis的高可用。哨兵机制实现原理： 哨兵会主动给主机发送心跳检测，如果主机三次没有响应，则会推选出从机代替成为新的主机。 当新的主机被推选之后，会修改所有的主从配置文件，重新实现主从挂载。 客户端无需关注谁是主机，只需要通过哨兵操作redis。 redis中hash一致性？ 均衡性：尽可能的让数据均匀的落在不同的节点上。虚拟节点可以有效的平衡数据量 单调性：如果节点的数量发生改变，则需要进行重新运算，节点中的数据可以重新挂载 分散性：在分布式系统中，由于部分操作看不到全部的内存空间，相同的key落入不同的位置 负载：在分布式系统中，由于部分操作看不到全部的内存空间，不同的key落到同一个位置 redis集群搭建？spring整合redis？redis作为分布式锁的使用？什么是redis分布式锁在分布式环境中，保证不同节点的线程同步执行。 分布式锁实现的三个核心：​ 1.加锁 setnx（key , 1） 当一个线程执行setnx返回1，说明原本的key不存在，该线程成功得到锁，否则说明该key已经存在，该线程抢锁失败。 2.解锁 del(key) 释放锁之后，其他线程就可以继续执行setnx命令来获得锁 3.超时锁 1.为什么要有超时锁？ 答：当一个得到锁的线程在执行任务的过程中挂掉，来不及显示的释放锁，那么这块资源将会永远被锁住，其他线程再也无法进入了。 setnx不支持超时参数，需要额外的指令： expire(key,30) redis分布式锁中三个致命的问题​ 场景一： 当某个线程执行setnx,成功得到了锁，但此时该节点挂了，却还没来得及执行expire指令，这样也会导致锁一直无法释放，即它们的执行不是原子性的。 解决：（版本2.6.12以上版本） set(key,1,30,NX)取代setnx指令 场景二： 假如A线程得到了锁，且成功得到了锁，并且设置了超时时间为30s,但如果A线程执行的很慢，超过30秒还没有执行完成，此时锁已经被超时释放，线程B获得了锁，当A执行完后，通过del指令来释放锁，但B线程还没有执行完，此时A线程把B现成的锁给释放了 解决：可以在加锁的时候把当前线程的ID作为value，并在删除之前验证key对应的value是不是自己的线程ID。但是此时的判断和释放锁也不是原子性的，这里我们需要使用Lua脚本来实现，此时验证与释放为原子性操作了。 String luaScript = “if redis.call(‘get’,KEY[1])==ARGV[1] then return redis.call(‘del’,KEYS) else return 0 end” redisClient.eval(luaScript,Collections.singletonList(key),Collections.singletonList(threadId)); 线程ID在多个进程下不是全局唯一 。这里可以使用全局唯一的业务ID，或者在线程ID前加上机器id ​ 场景三：在场景二中出现了两个线程访问同一个被锁的代码块的情况如何解决？ 解决：让获得锁的线程开启一个守护线程，当主线程快过期但还没有执行结束时，为其续航，当主线程真正执行完成后，再显示的关掉守护线程 另一种更优雅的实现方式，Zookeeper分布式锁 zookeeper的可靠性是要大于使用redis实现的分布式锁的，但是相比而言，redis的性能更好 redis官方推荐分布式锁：Redission 2.8.1的redisson需要jackson 2.5+版本 参考自：微信公众号-程序员小灰 当一个线程请求加锁失败了怎么办？重试策略： 直接抛出异常，通知用户稍后重试； sleep 一会再重试； 将请求转移至延时队列，过一会再试； redis作为消息队列使用？场景：用户下单，将用户生成展示的订单先处理完成，其他操作，则存入消息队列中，这样可以更快的响应用户请求，体验更好。 redis中常用的操作命令？http://www.redis.cn/commands.html 缓存和数据库双写数据一致性如何保证？数据的一致性，包括强一致性和最终一致性，要求强一致性，则不要使用缓存。最终一致性也只是降低不一致发生的概率，无法完全避免。 读取数据一般没啥问题，主要是更新数据。 三种策略： 1.先更新数据库，再更新缓存 问题：线程安全问题,多线程更新，并发情况下脏读。在写多读少的情况下，缓存频繁更新，但很少使用到，浪费性能。（不推荐） 2.先删除缓存，再更新数据库 并发场景下，A线程更新，B线程读取,A删除了缓存，还没来得及更新数据库，此时B查询缓存无数据，进而查询数据库，再更新缓存，这将导致缓存中的值永远为旧的值（不设置过期时间，或者回收的情况下）。 解决：延时双删策略：就是在A更新完数据库1S(根据业务逻辑时间)后，再次删除缓存（开启另外一个线程） 3.先更新数据库，再删除缓存 首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 参考：https://www.cnblogs.com/rjzheng/p/9041659.html 4.先更新缓存，再更新数据库 淘宝的一个场景读多写多 ，sql无序，使用过。 《从P1到P7——我在淘宝这7年》这篇博客原文 ： 在【招财进宝】项目中有一个技术的细节值得拿出来说说，淘宝商品详情页面每天的流量在10亿以上，里面的内容都是放在缓存里的，做【招财进宝】的时候，我们要给卖家显示他的商品被浏览的次数，这个数字必须实时更新，而用缓存的话一般都是异步更新的。于是商品表里面增加了这样一个字段，每增加一个PV这个字段就要更新一次。发布上去一个小时数据库就挂掉了，撑不住这么高的update。数据库撑不住怎么办？一般的缓存策略是不支持实时更新的，这时候多隆大神想了个办法，在apache上面写了一个模块，这个数字根本不经过下层的web容器（只经过apache）就写入一个集中式的缓存区了，这个缓存区的数据再异步更新到数据库。好像什么问题，到了多隆手里，总能迎刃而解。 redis是单线程的为什么那么快？ 纯内存操作 单线程操作，避免了上下文的切换 采用了非阻塞式I/O多路复用机制（NIO） 参考：https://www.cnblogs.com/rjzheng/p/9096228.html redis缓存雪崩，缓存穿透，缓存并发？ 缓存穿透：场景：缓存穿透是指使用不存在的key进行大量的高并发访问，导致缓存无法命中，造成数据库压力过大，甚至压死。解决方案： 将所有数据hash到一个大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉。 将空的结果也放入缓存中，但给它一个默认值，并设置一个很短的生存时间这样第二次再访问就有值了，就不会访问数据库了。 缓存并发：场景：在高并发场景下，当一个缓存的key过期时，而当前key的访问量比较大，多个请求同时发现缓存过期，因此会访问数据库，导致数据库压力过大。解决方案： 分布式锁 本地锁（当一个服务有多个节点时不适用） 软过期（在业务数据中存储过期时间信息，由业务程序判断是否过期并更新，发现数据将要过期时，延长缓存的时间，同时派遣另一条线程去数据库获取最新的数据） 缓存雪崩：场景：缓存服务器重启或者大量的缓存在同一时间段内失效，导致数据库瞬时压力过大。解决方案：对不同的数据使用不同的失效时间，如基础时间上加一个随机时间。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
</search>
