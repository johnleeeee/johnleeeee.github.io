<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[solr基础小结]]></title>
    <url>%2F2018%2F12%2F11%2Fsolr%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是solrSolr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。摘自百度百科。 环境：CentOS7+tomcat8.5+Java8+solr7.5+mysql8.5 2.solr在Linux下的安装安装jdk省略 到你想下载到的目录下下载solr： wget http://mirror.bit.edu.cn/apache/lucene/solr/7.5.0/solr-7.5.0.tgz 解压 tar -zxvf solr-7.5.0.tgz 启动 cd solr-7.5.0bin/solr start启动，会有警告提示，根据提示，执行bin/solr start -force启动完成后日志上会看到默认的端口port 8983 在浏览器上访问 ip:8983/solr即可访问 这种方式虽然简单，但是solr为我们做的太多，目录过于臃肿，也不便于我们移植扩展，尤其是当我们需要多个solr实例的时候。 3.solr部署到tomcat安装tomcat省略 将solr-7.5.0/server/solr-webapp目录下的内容copy到tomcat/webapps，并重命名为solr没加-r会报错：cp: 略过目录”/usr/local/src/solr/solr-7.5.0/server/solr-webapp/webapp”cp -r solr-7.5.0/server/solr-webapp/webapp webapps/solr 将solr-7.5.0/server/solr目录下的内容copy到solr-home下，solr-home自行创建，这是存放solr的一些配置文件的。mkdir solr-homecp -r /usr/local/src/solr/solr-7.5.0/server/solr/* solr-home/或者直接（事先不创建solr-home文件夹）cp -r /usr/local/src/solr/solr-7.5.0/server/solr solr-home/ 修改tomcat/webapps/solr项目的web.xml文件添加如下配置，如果没有就直接添加即可。 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/usr/local/src/solr-tomcat/solr-home&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt; &lt;/env-entry&gt; 复制依赖jar包 复制solr-7.5.0/server/lib/ext/下所有jar到tomcat/webapp/solr/WEB-INF/lib/下​ cp solr-7.5.0/server/lib/ext/* WEB-INF/lib/ 复制solr-7.5.0/server/lib下所有matrics开头的jar到tomcat/webapp/solr/WEB-INF/lib/下​ cp solr-7.5.0/server/lib/metrics-* WEB-INF/lib/ 复制solr/solr-7.5.0/dist/下的solr-clustering-7.5.0.jar solr-dataimporthandler-extras-7.5.0.jarsolr-dataimporthandler-7.5.0.jar两个jar复制到tomcat/webapp/solr/WEB-INF/lib/下​ cp solr-7.5.0/dist/solr-clustering-7.5.0.jar WEB-INF/lib/​ cp solr-7.5.0/dist/solr-dataimporthandler-7.5.0.jar WEB-INF/lib/​ cp solr-7.5.0/dist/solr-dataimporthandler-extras-7.5.0.jar WEB-INF/lib/ 复制其他配置 复制solr-7.5.0/server/resources/log4j.properties配置文件到tomcat/webapps/solr/WEB-INF/lib/下或者tomcat/webapps/solr/WEB-INF/classes目录下​ mkdir classes​ cp solr-7.5.0/server/resources/log4j* classes/ 启动tomcat 在浏览器上访问：ip:端口/solr/index.html 如果显示访问被拒绝，注释掉tomcat/solr下的web.xml的 12345678&lt;!--&lt;security-constraint&gt; &lt;web-resource-collection&gt; &lt;web-resource-name&gt;Disable TRACE&lt;/web-resource-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;http-method&gt;TRACE&lt;/http-method&gt; &lt;/web-resource-collection&gt; &lt;auth-constraint/&gt; &lt;/security-constraint&gt;--&gt; 保存后，稍等片刻重新访问即可。 4.solr的基本配置使用 Add Core 此时会提示缺少solrconfig文件，将solr-7.5.0/server/solr/configsets/_default/conf文件夹复制到solr-home/Student下cp -r /usr/local/src/solr/solr-7.5.0/server/solr/configsets/_default/conf Students/再次点击Add Core，即可添加成功，并且此时再新建的Core：Students下新创建了两个文件/文件夹 core.properties（该core基本配置信息）和data（该core的数据目录） 5.配置中文分词器两种任选一种 solr自带中文分词器 将solr-7.5.0\contrib\analysis-extras\lucene-libs下的lucene-analyzers-smartcn-7.5.0.jar放到tomcat\webapps\solr\WEB-INF\lib下在创建的Core的文件夹下的conf配置文件夹下的managed-schema添加如下配置即可 12345678&lt;fieldType name="text_ik_zd" class="solr.TextField" positionIncrementGap="100"&gt; &lt;analyzer type="index"&gt; &lt;tokenizer class="org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory"/&gt; &lt;/analyzer&gt; &lt;analyzer type="query"&gt; &lt;tokenizer class="org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory"/&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; 配置IK中文分词器 本篇配置用的是GitHub上下载jar包ik-analyzer-solr7将jar包copy到tomcat/webapps/solr/WEB-INF/lib目录下，将配置文件复制到classes目录下，详细参考GitHub上的教程。在创建的Core的文件夹下的conf配置文件夹下的managed-schema添加如下配置即可 12345678&lt;fieldType name="text_ik" class="solr.TextField"&gt; &lt;analyzer type="index"&gt; &lt;tokenizer class="org.apache.lucene.analysis.ik.IKTokenizerFactory" useSmart="true"/&gt; &lt;/analyzer&gt; &lt;analyzer type="query"&gt; &lt;tokenizer class="org.apache.lucene.analysis.ik.IKTokenizerFactory" useSmart="true"/&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; 查看效果 6.连接数据库 在tomcat/webapps/solr/WEB-INF/lib目录下添加数据库驱动包mysql-connector-java-8.0.12.jar 修改core：Students的conf配置文件下的solrconfig.xml ，添加如下配置： 12345&lt;requestHandler name="/dataimport" class="solr.DataImportHandler"&gt; &lt;lst name="defaults"&gt; &lt;str name="config"&gt;data-config.xml&lt;/str&gt; &lt;/lst&gt; &lt;/requestHandler&gt; 在同一目录下新建data-config.xml，配置数据源信息 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;dataConfig&gt; &lt;dataSource name="mytest" type="JdbcDataSource" driver="com.mysql.cj.jdbc.Driver" url="jdbc:mysql://yourip:3306/mytest?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;autoReconnect=true&amp;amp;allowMultiQueries=true&amp;amp;DatabaseName=mytest" user="用户名" password="密码"/&gt; &lt;document name="Students"&gt; &lt;entity pk="sid" dataSource="mytest" name="student" query="select sid,name,age,class_id,b_type from students"&gt; &lt;field column="sid" name="sid"/&gt; &lt;field column="name" name="name"/&gt; &lt;field column="age" name="age"/&gt; &lt;field column="class_id" name="classId"/&gt; &lt;field column="b_type" name="bookType"/&gt; &lt;/entity&gt; &lt;/document&gt;&lt;/dataConfig&gt; 添加对应数据库字段的field 可直接在managed-schema文件中直接添加 1&lt;field name="name" type="string" indexed="true" stored="true"/&gt; 也可使用管理平台进行添加，选择对应的core选择scheme，选择Add Field,添加对应的field 数据库数据导入 配置文件修改完成后，打开浏览器solr管理页面，进入Cord Admin重载code配置：reloadCode Selector选择对应code，进入Dataimport界面，导入数据：切换至Query界面点击查询，即可看到导入的数据。PS：每次修改配置文件，都需要重新执行导入，重建索引 清空数据：切换至Documents界面，Document Type选择XML，输入以下Document(s)并提交： 1&lt;delete&gt;&lt;query&gt;*:*&lt;/query&gt;&lt;/delete&gt;&lt;commit/&gt; 再次Query即可发现，数据已经清空。 7.在spring中的基本使用增删改查，搜索关键字高亮显示 Pom.xml 1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.magese&lt;/groupId&gt; &lt;artifactId&gt;ik-analyzer&lt;/artifactId&gt; &lt;version&gt;7.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt; &lt;version&gt;7.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; solr.properties 1SOLR.URL=http://ip:8080/solr/Students spring-solr 123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt;&lt;context:property-placeholder location="classpath:/properties/solr.properties"/&gt; &lt;bean id="httpSolrClient" class="org.apache.solr.client.solrj.impl.HttpSolrClient"&gt; &lt;constructor-arg name="builder" ref="builder"/&gt; &lt;!-- 设置响应解析器，solrj没有提供json解析器，所以通常用xml解析器 --&gt; &lt;property name="parser"&gt; &lt;bean class="org.apache.solr.client.solrj.impl.XMLResponseParser"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="builder" class="org.apache.solr.client.solrj.impl.HttpSolrClient.Builder"&gt; &lt;constructor-arg name="baseSolrUrl" value="$&#123;SOLR.URL&#125;"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; Students.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package net.keenlee.solrtest;import org.apache.solr.client.solrj.beans.Field;import java.io.Serializable;/** * @author lzq 2018/12/10 23:27 */public class Students implements Serializable &#123; @Field(value = "sid") private Integer sid; @Field(value = "name") private String name; @Field(value = "age") private Integer age; @Field(value = "classId") private Integer classId; @Field(value = "bookType") private Integer bookType; public Students(Integer sid, String name, Integer age, Integer classId, Integer bookType) &#123; this.sid = sid; this.name = name; this.age = age; this.classId = classId; this.bookType = bookType; &#125; public Students() &#123; super(); &#125; public Integer getSid() &#123; return sid; &#125; public void setSid(Integer sid) &#123; this.sid = sid; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name == null ? null : name.trim(); &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public Integer getClassId() &#123; return classId; &#125; public void setClassId(Integer classId) &#123; this.classId = classId; &#125; public Integer getBookType() &#123; return bookType; &#125; public void setBookType(Integer bookType) &#123; this.bookType = bookType; &#125; @Override public String toString() &#123; return "Students&#123;" + "sid=" + sid + ", name='" + name + '\'' + ", age=" + age + ", classId=" + classId + ", bookType=" + bookType + '&#125;'; &#125;&#125; SolrTest 123456789101112131415161718192021222324252627282930313233package net.keenlee.solrtest;import org.apache.solr.client.solrj.SolrQuery;import org.apache.solr.client.solrj.impl.HttpSolrClient;import org.apache.solr.client.solrj.response.QueryResponse;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.util.List;/** * @author lzq 2018/12/10 23:11 */public class SolrTest &#123; @Test public void solrDemo()&#123; ApplicationContext context = new ClassPathXmlApplicationContext("classpath:/spring/spring-solr.xml"); HttpSolrClient httpSolrClient = context.getBean("httpSolrClient", HttpSolrClient.class); //创建请求对象 SolrQuery query = new SolrQuery("name:lzq"); query.setStart(0); //分页操作 query.setRows(20); try &#123; QueryResponse queryResponse = httpSolrClient.query(query); List&lt;Students&gt; itemList = queryResponse.getBeans(Students.class); //由于查询的数据是document这样的对象其中包含属性值field,需要将 //field中的属性值自动的为item对象赋值. System.out.println(itemList); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 搜索结果： 8.solrCould+zookeeper集群配置9.总结]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>lucene</tag>
        <tag>solr</tag>
        <tag>全文搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins部署Java项目基础小结]]></title>
    <url>%2F2018%2F12%2F02%2FJenkins%E9%83%A8%E7%BD%B2Java%E9%A1%B9%E7%9B%AE%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是Jenkins？Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。 2.安装 安装配置jdk 安装配置maven 安装Jenkins cd /opt 下载 wget http://mirrors.jenkins.io/war/2.83/jenkins.war 启动 java -jar jenkins.war &amp; 第一次启动会生成一个随机密码口令，cpoy该口令密码 浏览器访问：http://localhost:8080/ 默认端口8080 可手动指定端口java -jar jenkins.war–httpPort=8081 第一进入需要输入上面复制的随机密码口令，即可进入配置 3.配置 进入插件安装界面，我们选择Install suggested plugins，官方推荐插件 进入了插件安装进度页，插件一次安装可能有些不成功，可点击retry重试，但我有两个无论咋retry都没有就直接跳过了，目前也没啥影响=_=!!! 进入用户创建页，输入信息，创建用户 登录成功后，进入主页，开始配置jdk路径。选择系统管理–&gt;全局工具配置，开始配置jdk，不选择自动安装。JAVA_HOME配置上面安装的目录地址。 配置Maven，不选择自动安装，MAVEN_HOME配置上面安装的目录地址 安装插件，很多插件是默认安装的，我们需要选择的插件Git plugin和Maven Integration plugin，publish over SSH。没有搜到的可能是已经安装过了，可以去已经安装的目录下看看。其他插件根据实际需要选择安装。 配置SSH免登录，配置Jenkins服务器与应用服务器的免密登录。 在Jenkins服务器生成密钥：ssh-keygen -t rsa 确认保存文件直接回车默认，并设置了私钥文件的密码，会在/root/.ssh目录下生成了私钥id_rsa和公钥id_rsa.pub，该目录为隐藏目录。ssh-keygen -t rsa -c 你的邮箱。-c表示这个key所有的一个注释，为邮箱，不写-c 你的邮箱的话，会默认为：用户名@localhost.localdomain 在应用服务器执行相同的操作 将Jenkins服务器的公钥复制到应用服务器的.ssh/authorized_keys文件中，该文件不用创建，执行下面的命令即可ssh-copy-id -i /root/.ssh/id_rsa.pub 用户名@应用服务器的ip 如果权限不够chmod 644 authorized_keys 执行时需要输入密码，即当前连接的用户名的登录密码。 重启应用服务器上的ssh服务，service sshd restart 测试是否可以免密登录，在A服务器执行 ：ssh 用户名@应用服务器ip。此时连接还是需要密码，但不是登录连接的密码，而是因为本地的私钥文件有加密密码，我们可以使用openssl取消密码。还有注意关闭防火墙。 退出连接，执行exit即可 配置Push SSH 选择系统管理–&gt;系统设置–&gt;选择Publish over SSH Passphrase：为私钥文件的密码 Path to key：私钥文件的地址：/root/.ssh/id_rsa SSH Servers 下的配置 ​ Name：规则内随便起名 Hostname：应用服务器的地址 Username：用户名 Remote Directory：这个远程地址即文件copy的地址，如：/usr/local/src/tomcat/apache-tomcat-8.5.35/，选择Add可配置多个应用服务器。 4.部署项目 选择新建任务，输入项目名称，名称需要与部署的项目名一致。选择构建一个maven项目，点击确定。 项目配置 通用配置，选择丢弃旧的构建，保持构建天数10天，保持最大的构建个数10个 源码管理，选择版本控制工具，这里用svn，所以选择Subversion Repository URL：项目的URL地址。如：http://172.16.*.*/svn/repos/simpledemo/trunk@HEAD，@HEAD意思取最新版本。 Credentials:添加Add：也就是该仓库的用户密码 构建环境：勾选Add timestamps to the Console Output Pre Steps：build前的操作设置 Build：在Build中输入打包前的mvn命令，如clean install -Dmaven.test.skip=true -Ptest #排除测试的包内容，即后缀为test的配置文件。 Post Steps ：选择 Run only if build succeeds SSH Server的name与前面全局配置下的Server选择对应的 Transfers ​ source files：Jenkins服务器下下来的项目打包的源文件，如target/simpledemo.jar ​ Remove profix：即复制过去的时候去除前缀，如target/ ​ Remote directory: 将项目复制到应用服务器的地址，再加上前面全局配置的Remote directory，就是完整的地址。如：webapps/，则此时的完整路径为：/usr/local/src/tomcat/apache-tomcat-8.5.35/webapps/ ​ Exec command：执行可执行文件。如；sh Jenkins-in/data-in.sh，即应用服务器，该地址下配置该脚本文件，即地址：/root/Jenkins-in/data-in.sh 可执行脚本文件 脚本文件可按照如下书写（该脚本添加在应用服务器/root/Jenkins-in/data-in.sh下，即Exec command配置的路径）： 普通的Java项目，部署到tomcat下 12345678910111213141516171819202122#! /bin/bash#java enviromentexport JAVA_HOME=/usr/local/src/java/jdk1.8.0_191export CLASSPATH=.:$&#123;JAVA_HOME&#125;/jre/lib/rt.jar:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jarexport PATH=$PATH:$&#123;JAVA_HOME&#125;/bintomcat_home=/usr/local/src/tomcat/apache-tomcat-8.5.35SHUTDOWN=$tomcat_home/bin/shutdown.shSTARTTOMCAT=$tomcat_home/bin/startup.shecho "关闭$tomcat_home"$SHUTDOWN#杀死tomcat进程ps -ef|grep tomcat|grep java|awk '&#123;print $2&#125;'|xargs kill -9#删除日志文件，如果你不先删除可以不要下面一行rm $tomcat_home/logs/* -rf#删除tomcat的临时目录rm $tomcat_home/work/* -rfsleep 5echo "启动$tomcat_home"$STARTTOMCAT#看启动日志#tail -f $tomcat_home/logs/catalina.out Springboot项目部署 12345678910111213141516171819202122232425TE=$(date +%Y%m%d)export JAVA_HOME PATH CLASSPATHJAVA_HOME=/usr/local/src/java/jdk1.8.0_191PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$CLASSPATHDIR=/root/simpledemoJARFILE=simpledemo.jarif [ ! -d $DIR/backup ];then mkdir -p $DIR/backupficd $DIRps -ef | grep $JARFILE | grep -v grep | awk '&#123;print $2&#125;' | xargs kill -9mv $JARFILE backup/$JARFILE$DATEmv -f /root/Jenkins-in/$JARFILE .java -jar $JARFILE &gt; out.log &amp;if [ $? = 0 ];then sleep 30 tail -n 50 out.logficd backup/ls -lt|awk 'NR&gt;5&#123;print $NF&#125;'|xargs rm -rf kill旧项目，删除旧项目，启动新项目，备份老项目 5.构建项目 选择需要构建的项目，点击立即构建即可 当构建完成后在Build History有构建的历史，可点击进入，可查看当前构建的信息 当构建失败，或者显示构建成功，但通过浏览器无法访问，可选择Console Output查看当前构建的日志信息，通过日志找出问题，解决即可。 6.总结以现在的学习和用途来看，Jenkins就是一个可配置的，从代码仓库下载打包文件，然后复制到服务器，通过ssh远程执行服务器的脚本文件，实现项目的部署，同时还有一些更高级的配置，方便我们部署，管理，测试。]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo-next搭建本站]]></title>
    <url>%2F2018%2F11%2F30%2F%E5%9F%BA%E4%BA%8Ehexo-next%E6%90%AD%E5%BB%BA%E6%9C%AC%E7%AB%99%2F</url>
    <content type="text"><![CDATA[环境： 安装git 安装node.js 安装hexo 插件： 微博图床 网易云音乐外链 leanCloud:访问量统计 valine评论 不蒜子：全站总访问量 hexo-wordcount:字数统计，阅读量统计等 addthis社会化分享 daovoice在线沟通 fontawesome矢量图标 Gulp博文压缩 腾讯公益404 功能： 1.访问人数统计 2.文章阅读次数 3.文章字数 4.文章阅读时长预测 5.博客总字数 6.文章加密 7.社会化分享 8.文章评论 9.在线沟通 10.网易云音乐播放外链 11.站外链接 12.友情链接 13.站点运行时间 14.博客粒子背景 15.跳动红心 16.文章赞赏 17.标签优化 18.文章结束提示语 19.首页头部美化 20.GitHub角标 21.腾讯公益404 22.文章版权信息 23.移动端与网页端差异化展示 参考文档： … 待完善的功能： 博客宠物 图片板块 音乐板块]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>hero-next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7搭建SVN服务基础小结]]></title>
    <url>%2F2018%2F11%2F27%2FCentOS7%E6%90%AD%E5%BB%BASVN%E6%9C%8D%E5%8A%A1%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.下载安装环境：CentOS7，subversion-1.7.14 查看是否已经安装过find / -name subversion 开始安装yum install subversion 查看安装目录rpm -pl subversion 查看一下系统是否默认绑定了svn根目录路径ps -ef|grep svnserve如果已经绑定则 kill -9 pid 2.创建仓库注意仓库根目录与版本库的区别 创建仓库根目录mkdir -p /var/svn/svnrepos 创建项目版本库cd /var/svn/svnrepossvnadmin create testsvn 3.修改版本库配置 cd testsvn/conf ls authz passwd svnserve.conf authz 是权限控制文件(添加用户和分组及它们的读写权限)vi authz[/] #权限的目录，此处为仓库下的所有文件admin=rw #可读写test1=r #可读*= #通配其它，无权限 另可配置分组权限配置[groups]group1 = admingroup2 = test1,test2[/]@group1 = rw@group2 = r*=r此时admin与test1可读可写，test2只可读 passwd 是帐号密码文件vi passwdadmin=123456 #账号=密码 svnserve.conf 是SVN服务配置文件vi svnserve.conf打开下面的5个注释anon-access = read #匿名用户可读auth-access = write #授权用户可写password-db = passwd #使用哪个文件作为账号文件（就是上面的那个文件）authz-db = authz #使用哪个文件作为权限文件（就是上面的那个文件）realm = /var/svn/svnrepos # 认证空间名，版本库所在目录注意：删除#号注释时前面不要留空格，否则后面连接时会报错 4.启动与关闭 启动服务svnserve -d -r /var/svn/svnrepos #-d表示守护进程， -r表示在后台执行 关闭服务ps -ef|grep svnservekill -9 pid 5.客户端连接注意关闭防火墙systemctl stop firewalld.service查看防火墙状态firewall-cmd –state windows可使用TortoiseSVN，Mac上可使用cornerstone。也可以使用eclipse，idea等开发工具连接输入地址格式：svn://ip:port/版本库名称（默认端口3690）如：svn://ip:3690/testsvn]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>centos7</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ基础小结]]></title>
    <url>%2F2018%2F09%2F11%2Frabbitmq%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是RabbitMQ？RabbitMQ作为消息中间件，可以平衡数据库压力，实现入库的异步操作，是一个在AMQP基础上完成的，可复用的企业消息系统。Broker：简单来说就是消息队列服务器实体。 Exchange：消息交换机，它指定消息按什么规则，路由到哪个队列。 Queue：消息队列载体，每个消息都会被投入到一个或多个队列。 Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来。 Routing Key：路由关键字，exchange根据这个关键字进行消息投递。 vhost：虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 producer：消息生产者，就是投递消息的程序。 consumer：消息消费者，就是接受消息的程序。 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 原理图： 思维导图： 参考：https://www.cnblogs.com/linkenpark/p/5393666.html 2.RabbitMQ的工作模式？ 简单模式 提供者将消息写入队列，如果队列中没有其他消息，则消息会在第一时间被处理消费者会实时监控队列中是否有消息，如果有则进行处理 工作模式／双工模式 由一个生产者生产，多个消费者进行争抢，谁抢到谁执行 发布订阅模式（fanout） 生产者通过交换机，将消息发往不同的队列，每个消费者只关注自己的队列，对自己的队列消息进行消费（一个消息被消费多次，适合群发和广播） 路由模式（redirect） 消费者通过交换机，根据不同的路由key将消息发往不同的队列中，通过路由key的比较，将消息发往特定消费者的队列中（特殊的订阅模式） 主题模式（topic） 通过通配符*（一个或多几个字符）或#（任意类型，可以匹配多个字符串）将消费发往匹配的路由key的消息队列中（特殊的路由模式） 参考：http://www.rabbitmq.com/getstarted.html 3.具体应用场景？4.如何保证消息队列的消息一定被消费？如何保证消息不被重复消费？如何保证消息的执行顺序？Rabbit通过Ack机制机制上，通过先缓存发送的消息，直到得到Ack再删除message，否则从新发送消息，可开启一条线程来进行消息超时的检查。来确保消费被正确发送和消费。 开启持久化策略，保证服务器在宕机时，消息不会丢失，当会影响性能。当消息被消费，但返回ACK出现问题，会导致，消息重发，重复消费，需要保证业务逻辑的幂等性。可以用db记录消息的消费状态（取消／失败／成功）表示已经被消费了。直接返回ack消息。 5.RabbitMQ在项目中的使用步骤？spring-rabbit整合？ 导入jar包。（新版本的包各种报错，搞不来…） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 创建rabbitmq.properties文件。 12345rabbit.ip=172.16.81.134rabbit.port=5672rabbit.username=lzqrabbit.password=123virtual-host=/ 配置spring-Rabbit-send.xml文件，创建连接工厂／创建交换机（可配置自动持久化）／定义rabbitTemplate模版配置连接工厂 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation="http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd"&gt; &lt;!-- 定义RabbitMQ的连接工厂 --&gt; &lt;rabbit:connection-factory id="connectionFactory" host="$&#123;rabbit.ip&#125;" port="$&#123;rabbit.port&#125;" username="$&#123;rabbit.username&#125;" password="$&#123;rabbit.password&#125;" virtual-host="$&#123;virtual-host&#125;"/&gt; &lt;!-- MQ的管理，包括队列、交换器等 --&gt; &lt;rabbit:admin connection-factory="connectionFactory"/&gt; &lt;!-- 定义交换机 自动声明 持久化--&gt; &lt;rabbit:direct-exchange name="orderExchange" auto-declare="true" durable="true" /&gt; &lt;!--定义rabbit模板--&gt; &lt;rabbit:template id="rabbitTemplate" connection-factory="connectionFactory" exchange="orderExchange"/&gt;&lt;/beans&gt; 配置连接工厂／定义消息队列／定义交换机（绑定队列，定义路由key）／定义监听，配置监听服务，方法，监听的队列 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation="http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd"&gt; &lt;!-- 1.定义RabbitMQ的连接工厂 --&gt; &lt;rabbit:connection-factory id="connectionFactory" host="$&#123;rabbit.ip&#125;" port="$&#123;rabbit.port&#125;" username="$&#123;rabbit.username&#125;" password="$&#123;rabbit.password&#125;" virtual-host="$&#123;virtual-host&#125;" /&gt; &lt;!-- MQ的管理，包括队列、交换器等 --&gt; &lt;rabbit:admin connection-factory="connectionFactory" /&gt; &lt;!-- 定义消息队列 --&gt; &lt;rabbit:queue name="orderQueue" auto-declare="true"/&gt; &lt;!-- 定义交换机，并且完成队列和交换机的绑定 --&gt; &lt;rabbit:direct-exchange name="orderExchange" auto-declare="true"&gt; &lt;rabbit:bindings&gt; &lt;!-- key：路由key --&gt; &lt;rabbit:binding queue="orderQueue" key="save.order"/&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; &lt;!--自定义bean处理消息队列中的内容--&gt; &lt;bean id="rabbitOrderListener" class="net.keenlee.pakchoi.test.listener.RabbitOrderListener"&gt;&lt;/bean&gt; &lt;!-- 定义监听 --&gt; &lt;rabbit:listener-container connection-factory="connectionFactory" acknowledge="auto"&gt; &lt;!-- 监听一个队列，当队列中有消息，就会自动触发类.方法，传递消息就作为方法的参数，根据方法声明的参数强转 --&gt; &lt;rabbit:listener ref="rabbitOrderListener" method="onMessage" queues="orderQueue"/&gt; &lt;/rabbit:listener-container&gt;&lt;/beans&gt; 使用rabbitTemplate操作消息队列 发送者： 123456789101112131415161718192021package net.keenlee.pakchoi.test.controller;import net.keenlee.pakchoi.test.service.RabbitMQOrderService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class TestRabbitmqController &#123; @Autowired RabbitMQOrderService rabbitMQOrderService; @RequestMapping("saveOrder") @ResponseBody public void saveOrder()&#123; //下单 rabbitMQOrderService.saveOrder(); &#125;&#125; 123456package net.keenlee.pakchoi.test.service;public interface RabbitMQOrderService &#123; void saveOrder();&#125; 12345678910111213141516171819202122package net.keenlee.pakchoi.test.service.impl;import net.keenlee.pakchoi.test.service.RabbitMQOrderService;import org.springframework.amqp.core.AmqpTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class RabbitMQOrderServiceImpl implements RabbitMQOrderService &#123; @Autowired AmqpTemplate rabbitTemplate; @Override public void saveOrder() &#123; //下单 System.out.println("订单保存成功！"); System.out.println("向消息队列发送消息..."); //发送邮件 rabbitTemplate.convertAndSend("save.order","恭喜你，下单成功！！！"); &#125;&#125; 接收者： 12345678910111213141516171819202122package net.keenlee.pakchoi.test.listener;import org.springframework.amqp.core.Message;import org.springframework.amqp.core.MessageListener;import java.io.UnsupportedEncodingException;public class RabbitOrderListener implements MessageListener &#123; @Override public void onMessage(Message message) &#123; try &#123; sendEmail(new String(message.getBody(),"utf-8")); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; public void sendEmail(String msg)&#123; System.out.println("接收到消息队列的消息:"+msg); &#125;&#125; 运行结果： 改造1:断开重试机制 改造2:消息确认消费 改造3:保证消息幂等性 改造4:…]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat配置基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fmycat%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.数据库热备原理？ 二进制日志文件。当主数据库发生更新时，会将更新的数据写入二进制文件中。 I／O线程。从机实时监听二进制文件是否有更新操作，如果有更新操作则读取更新的内容。 中继日志。保存主库更新的数据（临时存储）。 SQl线程。将中继日志的信息更新到数据库中。 2.如何配置主从数据库？ 为mysql的配置文件my.cnf，默认条件下的二进制日志文件是关闭的。 实现主从挂载（互为主从：双机热备）注意： server-id不能重复。 服务器不能连接：关闭防火墙／IP地址是否正确。 找不到日志文件：日志文件写错。 主从同步应注意哪些问题？当进行主从挂载时，post位置可以从0开始，但必须保证主从库表一致。进行主从同步时，都是由同一个sql转储文件导入之后再进行数据挂载，这样能极大的降低从库的负载，减轻数据不同步的影响 3.主从同步延时/不一致解决方案？4.mycat的作用？mycat是一个高性能的数据库中间件。 支持心跳检测机制，实现数据库的高可用 实现数据库的读写分离和主从复制 支持分库分表 5.mycat主从搭建？主要步骤及配置？mysql数据库实现了完善的数据库备份机制。 搭建主库： 开放数据库权限，导入数据库文件。 1grant all on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;root&apos;;（测试的时候all,开启起了所有权限，这是危险的） 开启二进制文件,编辑mysql系统配置文件my.cnf(指定mysql端口，数据库位置) 123456789[mysqld]#指定数据库存储路径datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysql#制定serverid，不能与集群中另一个相同server-id=1#开启二进制日志文件log-bin=mysql-bin 重启服务，检查二进制文件是否启动 cd /var/lib/mysql是否存在mysql-bin.000001。每次重启编号加1。 搭建从库： 与主库一样修改my.cnf文件，但server-id不能一样 主从连接: 查看主库状态SHOW MASTER status，查看它的position 1show master status 实现主从挂载 1234567#实现主从的挂载 主机的ip 端口 #用户名和密码 二进制日志文件 文件的位置change MASTER to MASTER_HOST=&quot;192.168.126.137&quot;,MASTER_PORT=3306,MASTER_user=&quot;root&quot;,MASTER_PASSWORD=&quot;root&quot;,MASTER_LOG_FILE=&quot;mysql-bin.000001&quot;,MASTER_LOG_POS=120 启动从服务器，查看从服务状态 12#检测主从服务启动是否正确 （查看Slave_IO_Runing=yes,Slave_SQL_Runing=yes）show SLAVE STATUS 如果slave_IO_Running和slave_SQL_Running的值为yes说明搭建成功。注意：单纯的主从会存在问题。当主库宕机整个服务都将无法使用，假设配置了一主多从，当主机宕机，从机成为新的主机，但与原有的从机不存在主从关系，导致数据无法同步，解决双机热备。 配置jdk，编写两个配置文件schema.xml和server.xml两个配置文件 schema.xml 主要配置： 配置dataNode：表示数据库节点信息（节点名称／节点主机／数据库名称） 配置dataHost：表示节点主机（节点主机名／最大连接数／最小连接数／读写分离策略（balance：0:读操作发往writeHost。1:读操作发往readHost和闲置主节 writeType：0:所有的写操作都会发往第一台writeHost中。1:写操作随机发往writeHost主机／数据库类型／数据库驱动／高可用切换类型switchType：-1不自动切换，1，自动切换心跳检测heratbeat）） 配置writeHost及对应的readHost（名字／IP：port／用户／密码） 123456789101112131415161718192021222324&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE mycat:schema SYSTEM "schema.dtd"&gt;&lt;mycat:schema xmlns:mycat="http://io.mycat/"&gt; &lt;!--name属性是自定义的 dataNode表示数据库的节点信息--&gt; &lt;schema name="mytest" checkSQLschema="false" sqlMaxLimit="100" dataNode="mytest"&gt;&lt;/schema&gt; &lt;!--定义节点名称/节点主机/数据名称--&gt; &lt;dataNode name="mytest" dataHost="localhost1" database="mytest" /&gt; &lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="1" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select 1&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="192.168.106.137:3306" user="root" password="Lzq_0221"&gt; &lt;!--读数据库--&gt; &lt;readHost host="hostS1" url="192.168.106.138:3306" user="root" password="Lzq_0221" /&gt; &lt;/writeHost&gt; &lt;!-- 需要实现双机热备 --&gt;&lt;writeHost host="hostM2" url="192.168.106.138:3306" user="root" password="Lzq_0221"&gt; &lt;readHost host="hostS1" url="192.168.106.137:3306" user="root" password="Lzq_0221" /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; server.xml主要配置： 设置防火墙／设置用户标签（用户名／用户密码／数据库要与schema中一致） 1234567&lt;!--用户标签--&gt; &lt;user name="root"&gt; &lt;property name="password"&gt;Lzq_0221&lt;/property&gt; &lt;!--与schema.xml中的配置相同 注意数据库的大小写--&gt; &lt;property name="schemas"&gt;mytest&lt;/property&gt; &lt;property name="readOnly"&gt;false&lt;/property&gt; &lt;/user&gt; 通过连接mycat来操作数据库 规则 rule.xml:mycat分片规则（分库分表）定义的规则为对id使用mod-log将数据库平均拆分。用function中count指定分配的物理库的数量。 支持的规则：固定分片hash算法／范围约定／求模法／日期列分区／一致性hash（可以解决动态扩容的问题） 6.分库分表策略，分库分表配置？ 答：使用mycat分片实现分库分表……]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>mycat</tag>
        <tag>数据库中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fdubbo%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是dubboApache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 2.dubbo的特性？ 面向接口代理的高性能RPC调用提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节。 智能负载均衡内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。 服务自动注册与发现支持多种注册中心服务，服务实例上下线实时感知。 高度可扩展能力遵循微内核+插件的设计原则，所有核心能力如Protocol、Transport、Serialization被设计为扩展点，平等对待内置实现和第三方实现。 运行期流量调度内置条件、脚本等路由策略，通过配置不同的路由规则，轻松实现灰度发布，同机房优先等功能。 可视化的服务治理与运维提供丰富服务治理、运维工具：随时查询服务元数据、服务健康状态及调用统计，实时下发路由策略、调整配置参数。 3.Dubbo工作原理？答：1.消费者2.提供者3.监视器（monitor）4.注册中心（zookeeper）1.消费者配置注册中心地址，添加依赖的服务接口及服务id2.提供者配置注册中心地址，配置dubbo服务接口，暴露服务接口，创建具体实现接口服务的bean 4.rpc原理5.Spring整合Dubbo？前提：搭建好了zookeeper作为注册中心。 创建Duubo接口 1234public interface StudentsDubboServiceInterface &#123; List&lt;Students&gt; findAll();&#125; 生产者 service实现dubbo接口 1234567891011@Servicepublic class StudentsServiceImpl implements StudentsDubboServiceInterface &#123; @Autowired StudentsMapper studentsMapper; @Override public List&lt;Students&gt; findAll() &#123; return studentsMapper.selectAll(); &#125;&#125; 配置生产者 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;!--定义了提供方应用信息，用于计算依赖关系；在 dubbo-admin 或 dubbo-monitor 会显示这个名字，方便辨识--&gt; &lt;dubbo:application name="demotest-provider" owner="programmer" organization="dubbox"/&gt; &lt;!--使用 zookeeper 注册中心暴露服务，注意要先开启 zookeeper--&gt; &lt;!--&lt;dubbo:registry address="zookeeper://192.168.106.128:2181"/&gt;--&gt; &lt;dubbo:registry protocol="zookeeper" address="192.168.106.128:2181,192.168.106.129:2181,192.168.106.130:2181" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;!--使用 dubbo 协议实现定义好的 api.PermissionService 接口--&gt; &lt;dubbo:service interface="net.keenlee.pakchoi.dubbo.service.StudentsDubboServiceInterface" ref="studentsDubboService" protocol="dubbo" timeout="10000" /&gt; &lt;!--具体实现该接口的 bean--&gt; &lt;bean id="studentsDubboService" class="net.keenlee.pakchoi.manager.service.impl.StudentsServiceImpl"/&gt;&lt;/beans&gt; 消费者 service实现dubbo接口 1234567891011@Servicepublic class StudentsServiceTestImpl implements StudentsServiceTest &#123; @Autowired StudentsDubboServiceInterface studentsDubboServiceInterface; @Override public List&lt;Students&gt; findAll() &#123; return studentsDubboServiceInterface.findAll(); &#125;&#125; 配置消费者 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="demotest-consumer" owner="programmer" organization="dubbox"/&gt; &lt;!--向 zookeeper 订阅 provider 的地址，由 zookeeper 定时推送--&gt; &lt;!--&lt;dubbo:registry address="zookeeper://192.168.106.128:2181"/&gt;--&gt; &lt;dubbo:registry protocol="zookeeper" address="192.168.106.128:2181,192.168.106.129:2181,192.168.106.130:2181" /&gt; &lt;!--使用 dubbo 协议调用定义好的 api.PermissionService 接口--&gt; &lt;dubbo:reference id="studentsDubboService" interface="net.keenlee.pakchoi.dubbo.service.StudentsDubboServiceInterface"/&gt;&lt;/beans&gt; dubbo官网：http://dubbo.apache.org/zh-cn/]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx基础小结]]></title>
    <url>%2F2018%2F08%2F20%2Fnginx%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.什么是nginx？Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。 2.反向代理？项目中使用场景？反向代理是指以代理服务器来接受网络请求，将请求转发给内部服务器，并将结果返回给给客户端。实现动静分离，在进行图片回显时由于我们无法直接访问服务器存在本地磁盘的图片文件，只能通过一个虚拟路径进行访问，该请求被代理服务器拦截，将虚拟路径替换为真实路径，最终通过代理将结果进行返回。 3.nginx负载均衡？ 轮询机制：upstream 集群名称{}:根据配置文件的顺序依次进行服务的调用。 权重机制：在集群中添加weight属性。 ip_hash:根据用户的IP地址进行hash运算，最终算出特定的一台机器进行数据转发（如果配置ip_hash权重和轮询将不起作用）。 backup：备用机机制，当主服务正忙或者断电／宕机时，备用机将会起作用。 4.nginx基本配置？123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#运行用户#user nobody;#启动进程，通常设置成和cpu的数量相等worker_processes 1;#全局错误日志文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid文件#pid logs/nginx.pid;events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024;&#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k;#设定虚拟主机配置server&#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; error_log 错误日志路径; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125;location ／&#123; # proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root :定义服务器的默认网站根目录位置; index:定义首页索引文件的名称； proxy_pass: http://localhost:8091;//转发请求 或者proxy_pass: http://7080 #跟upstream合用 #定义超时策略 proxy_connect_timeout 1 proxy_send_timeout 1 proxy_read_timeout 1 &#125; #重定向：相对于proxy_pass，地址栏的路径会改变 location ^~ /oauth2/ &#123; rewrite /(.*) https://$host/$1 permanent; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125;&#125;#指定proxy_pass代理路径,均衡策略，最大连接失败次数，超时失败时间upstream 7080 &#123; server ip1:7080 weight=5 max_fails=2 fail_timeout=30s; #server ip1:7080 weight=3 max_fails=2 fail_timeout=30s; #server ip2:7080 weight=2 max_fails=2 fail_timeout=30s;&#125;#引入其它配置文件include servers/*;include ***.conf; &#125; 5.正向代理与反向代理的区别？6.nginx如何实现tomcat的高可用？在nginx连接服务器期间，会自动向服务器发送健康检查机制（ping/发起一次请求）如果服务器失败的次数达到最大失败次数（max_fail）上限，在这个检测周期(fail_timeout)中，将不会再有请求转发到这个服务器上，直到下一次检测周期。 7.nginx进程模型？事件处理？8.与其他服务器的对比？9.nginx防盗链？]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础小结]]></title>
    <url>%2F2018%2F08%2F08%2FRedis%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[什么是redis？redis是一种内存中的数据结构存储系统，它可以用作数据库／缓存／消息中间件。 redis常见的作用？项目中使用redis作为缓存使用，这样可以减轻数据库的压力，同时可以加快一些常用数据的查询效率。对于查询多修改少的数据进行缓存。 数据库中的数据与缓存中的数据如何实现同步？同步是同程序员代码来实现控制的。具体操作是： 当缓存中不存在数据时，先去数据库查询，成功后更新缓存。 当缓存中存在数据时，首先更新缓存中的数据，同时会生成对应的修改操作的key一张记录表，之后redis后台会有相关的机制（待查。。。），读取该列表的保存的key，找到对应的数据，同步更新到数据库中。 缓存中的数据如何实现持久化操作？为什么要进行持久化操作？redis中有完善的持久化策略。 RDB（默认）：这种备份方式的效率最高，在规定的时间周期内为数据进行备份，如在多少秒内进行了多少次set操作则进行一次备份，保存在rdb文件中，当redis重启之后会根据配置文件找到对应的备份文件还原数据。 AOF：实时的持久化策略，性能相对较低。有三种模式： always：执行一次set就持久化一次。 everysec：每隔一秒进行一次持久化（常用）。 no：持久化的时间由操作系统决定。（一般不配） 因为redis中的数据保存在内存中，如果出现宕机或断电的情况，会使内存中的数据丢失。如果是当作数据库和消息队列来使用时，这样的数据是绝不允许丢失的。 redis如何管理维护自身内存大小的？redis有6种内存优化管理的策略。 lru：删除最近最少使用的数据 volatile-lru:删除设定了超时时间的数据中找最近最少使用的数据 allkey-lru：所有的key根据lru算法进行删除 volatile-random：在设定了超时时间的数据中进行随机删除 allkey-random：在所有的key中进行随机删除 volatile-ttl：在设置了超时时间的数据中删除，将要超时的数据 noevication：默认策略，不会进行删除，当进行set操作时会返回报错信息 缓存中的数据结构是怎样的？支持的数据类型有哪些？redis数据是通过key-value方式进行存储的。 redis支持五种基础数据类型： string（字符串）：redis字符串是动态的，内部结构类似于Java的ArrayList，字符串最大长度为 512M 。 hash（哈希）：类似于Java的HashMap，数组+链表。不同的是字典的值只能是字符串，同时采用的是渐进式rehash策略。即保存了，新旧两个hash表，知道rehash全部完成，删除旧的。 hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。 hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。 list（列表）：类似于Java的LinkList（quickList），当列表元素较少时，采用ziplist（压缩列表）结构，连续的存储空间，节省存储空间，减轻内存碎片化 。当列表元素较多时，采用quicklist。将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 set（集合）：类似于Java的HashSet，可用作全局去重 zset（sorted set：有序集合）：类似于SortedSet+HashMap，内部是跳跃列表的结构。 高级数据类型：HyperLogLog（），Geo、Pub/Sub （不成熟，基本被放弃），stream（5.0）支持消息订阅，想代替mq？ 简述redis分片？为什么需要redis分片？分片：根据某种规则… 分片的原因： redis内存满了，分片可实现动态扩容 redis服务器可能宕机，分片可以让每个节点保存一部分数据，宕机只会影响部分数据 简述redis哨兵机制？使用哨兵机制实现redis的高可用。哨兵机制实现原理： 哨兵会主动给主机发送心跳检测，如果主机三次没有响应，则会推选出从机代替成为新的主机。 当新的主机被推选之后，会修改所有的主从配置文件，重新实现主从挂载。 客户端无需关注谁是主机，只需要通过哨兵操作redis。 redis中hash一致性？ 均衡性：尽可能的让数据均匀的落在不同的节点上。虚拟节点可以有效的平衡数据量 单调性：如果节点的数量发生改变，则需要进行重新运算，节点中的数据可以重新挂载 分散性：在分布式系统中，由于部分操作看不到全部的内存空间，相同的key落入不同的位置 负载：在分布式系统中，由于部分操作看不到全部的内存空间，不同的key落到同一个位置 redis集群搭建？ 创建Cluster文件夹，复制配置文件，cluster/700*/7000-7008 修改配置文件 注释绑定 bind 127.0.0.1 关闭保护模式 protected-mode no 修改端口 port 7000 开启后台启动 daemonize yes 修改pid路径 pidfile 修改持久化文件路径 dir 修改内存策略 maxmemory-policy 启动redis集群 cluster-enabled yes 添加节点信息 cluster-config-file node-7000.conf 添加超时时间 cluster-node-timeout 15000 启动redis集群 复制配置文件 批量修改配置文件 :在配置文件中如“ :%s/7000/7001/g” 批量启动配置文件 创建批量脚本 sh start.sh 使用ruby工具构建集群 安装ruby，./configure （–prefix=***） make make install ruby -v 安装rubygems, ruby setup.rb 安装redis-gem， 将文件copy到rubygems根目录 执行​ gem install -l redis-*.gem 检查安装 gem list 构建集群，在redis的根目录下执行​ ./src/redis-trib.rb create –replicas 2 192.168.106.131:7000 192.168.106.131:7001 192.168.106.131:7002 192.168.106.131:7003 192.168.106.131:7004 192.168.106.131:7005 192.168.106.131:7006 192.168.106.131:7007 192.168.106.131:7008 测试 redis-cli中info replication,查看主从 redis5.0 redis-cli中集成了集群构建工具，不再需要ruby 安装过程的报错： 安装rubygem报错：/usr/local/src/ruby/rubygems-2.7.7/lib/rubygems/core_ext/kernel_require.rb:59:in `require’: cannot load such file – zlib (LoadError)。安装过程出现问题，尝试了网上的一些解决方法，无效。最后采用make distclean:将全部编译及生成的文件清除后重新进行安装，成功。 spring整合redis？redis作为分布式锁的使用？什么是redis分布式锁在分布式环境中，保证不同节点的线程同步执行。 分布式锁实现的三个核心：1.加锁 setnx（key , 1） 当一个线程执行setnx返回1，说明原本的key不存在，该线程成功得到锁，否则说明该key已经存在，该线程抢锁失败。 2.解锁 del(key) 释放锁之后，其他线程就可以继续执行setnx命令来获得锁 3.超时锁 1.为什么要有超时锁？ 答：当一个得到锁的线程在执行任务的过程中挂掉，来不及显示的释放锁，那么这块资源将会永远被锁住，其他线程再也无法进入了。 setnx不支持超时参数，需要额外的指令： expire(key,30) redis分布式锁中三个致命的问题场景一： 当某个线程执行setnx,成功得到了锁，但此时该节点挂了，却还没来得及执行expire指令，这样也会导致锁一直无法释放，即它们的执行不是原子性的。 解决：（版本2.6.12以上版本） set(key,1,30,NX)取代setnx指令 场景二： 假如A线程得到了锁，且成功得到了锁，并且设置了超时时间为30s,但如果A线程执行的很慢，超过30秒还没有执行完成，此时锁已经被超时释放，线程B获得了锁，当A执行完后，通过del指令来释放锁，但B线程还没有执行完，此时A线程把B现成的锁给释放了 解决：可以在加锁的时候把当前线程的ID作为value，并在删除之前验证key对应的value是不是自己的线程ID。但是此时的判断和释放锁也不是原子性的，这里我们需要使用Lua脚本来实现，此时验证与释放为原子性操作了。 String luaScript = &quot;if redis.call(&apos;get&apos;,KEY[1])==ARGV[1] then return redis.call(&apos;del&apos;,KEYS) else return 0 end&quot; redisClient.eval(luaScript,Collections.singletonList(key),Collections.singletonList(threadId)); 线程ID在多个进程下不是全局唯一 。这里可以使用全局唯一的业务ID，或者在线程ID前加上机器id 场景三：在场景二中出现了两个线程访问同一个被锁的代码块的情况如何解决？ 解决：让获得锁的线程开启一个守护线程，当主线程快过期但还没有执行结束时，为其续航，当主线程真正执行完成后，再显示的关掉守护线程 另一种更优雅的实现方式，Zookeeper分布式锁 zookeeper的可靠性是要大于使用redis实现的分布式锁的，但是相比而言，redis的性能更好 redis官方推荐分布式锁：Redission 2.8.1的redisson需要jackson 2.5+版本 参考自：微信公众号-程序员小灰 当一个线程请求加锁失败了怎么办？重试策略： 直接抛出异常，通知用户稍后重试； sleep 一会再重试； 将请求转移至延时队列，过一会再试； redis作为消息队列使用？场景：用户下单，将用户生成展示的订单先处理完成，其他操作，则存入消息队列中，这样可以更快的响应用户请求，体验更好。 redis中常用的操作命令？http://www.redis.cn/commands.html 缓存和数据库双写数据一致性如何保证？数据的一致性，包括强一致性和最终一致性，要求强一致性，则不要使用缓存。最终一致性也只是降低不一致发生的概率，无法完全避免。 读取数据一般没啥问题，主要是更新数据。 三种策略： 1.先更新数据库，再更新缓存 问题：线程安全问题,多线程更新，并发情况下脏读。在写多读少的情况下，缓存频繁更新，但很少使用到，浪费性能。（不推荐） 2.先删除缓存，再更新数据库 并发场景下，A线程更新，B线程读取,A删除了缓存，还没来得及更新数据库，此时B查询缓存无数据，进而查询数据库，再更新缓存，这将导致缓存中的值永远为旧的值（不设置过期时间，或者回收的情况下）。 解决：延时双删策略：就是在A更新完数据库1S(根据业务逻辑时间)后，再次删除缓存（开启另外一个线程） 3.先更新数据库，再删除缓存 首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 参考：https://www.cnblogs.com/rjzheng/p/9041659.html 4.先更新缓存，再更新数据库 淘宝的一个场景读多写多 ，sql无序，使用过。 《从P1到P7——我在淘宝这7年》这篇博客原文 ： 在【招财进宝】项目中有一个技术的细节值得拿出来说说，淘宝商品详情页面每天的流量在10亿以上，里面的内容都是放在缓存里的，做【招财进宝】的时候，我们要给卖家显示他的商品被浏览的次数，这个数字必须实时更新，而用缓存的话一般都是异步更新的。于是商品表里面增加了这样一个字段，每增加一个PV这个字段就要更新一次。发布上去一个小时数据库就挂掉了，撑不住这么高的update。数据库撑不住怎么办？一般的缓存策略是不支持实时更新的，这时候多隆大神想了个办法，在apache上面写了一个模块，这个数字根本不经过下层的web容器（只经过apache）就写入一个集中式的缓存区了，这个缓存区的数据再异步更新到数据库。好像什么问题，到了多隆手里，总能迎刃而解。 redis是单线程的为什么那么快？ 纯内存操作 单线程操作，避免了上下文的切换 采用了非阻塞式I/O多路复用机制（NIO） 参考：https://www.cnblogs.com/rjzheng/p/9096228.html redis缓存雪崩，缓存穿透，缓存并发？ 缓存穿透：场景：缓存穿透是指使用不存在的key进行大量的高并发访问，导致缓存无法命中，造成数据库压力过大，甚至压死。解决方案： 将所有数据hash到一个大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉。 将空的结果也放入缓存中，但给它一个默认值，并设置一个很短的生存时间这样第二次再访问就有值了，就不会访问数据库了。 缓存并发：场景：在高并发场景下，当一个缓存的key过期时，而当前key的访问量比较大，多个请求同时发现缓存过期，因此会访问数据库，导致数据库压力过大。解决方案： 分布式锁 本地锁（当一个服务有多个节点时不适用） 软过期（在业务数据中存储过期时间信息，由业务程序判断是否过期并更新，发现数据将要过期时，延长缓存的时间，同时派遣另一条线程去数据库获取最新的数据） 缓存雪崩：场景：缓存服务器重启或者大量的缓存在同一时间段内失效，导致数据库瞬时压力过大。解决方案：对不同的数据使用不同的失效时间，如基础时间上加一个随机时间。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>缓存</tag>
        <tag>消息队列</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
</search>
